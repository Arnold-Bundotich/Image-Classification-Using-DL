{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 1___\n",
    "\n",
    "#General libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "# ___Cell no. 2___\n",
    "\n",
    "#Imports for the Gabor filter\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.filters import gabor_kernel\n",
    "from scipy.stats import kurtosis, skew\n",
    "# ___Cell no. 3___\n",
    "\n",
    "#Import for preview of images\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ___Cell no. 4___\n",
    "\n",
    "#Load zebra images into an array\n",
    "zebrafolder = './zebra/'\n",
    "zebra_images = glob.glob('{}*.jpg'.format(zebrafolder))\n",
    "\n",
    "#Check how many images we have\n",
    "len(zebra_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "from matplotlib.image import imread\n",
    "import math\n",
    "\n",
    "def showImagesHorizontally(list_of_files):\n",
    "    fig = figure(figsize=(20,10))\n",
    "    number_of_files = len(list_of_files)\n",
    "    #c=math.ceil((number_of_files)/3)\n",
    "    for i in range(5):\n",
    "        a=fig.add_subplot(1,5,i+1)\n",
    "        image = imread(list_of_files[i])\n",
    "        imshow(image,cmap='Greys_r')\n",
    "        axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e20d0942268e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshowImagesHorizontally\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzebra_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-04ad2c80d618>\u001b[0m in \u001b[0;36mshowImagesHorizontally\u001b[1;34m(list_of_files)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Greys_r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImagesHorizontally(zebra_images[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 6___\n",
    "\n",
    "#Load random images into an array\n",
    "nozebrafolder = './nozebra/'\n",
    "nozebra_images = glob.glob('{}*.jpg'.format(nozebrafolder))\n",
    "\n",
    "#Check how many images we have\n",
    "len(nozebra_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImagesHorizontally(nozebra_images[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after looking the featur extraction is the same every where "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 8___\n",
    "\n",
    "#Function to perform feature extraction using the Gabor filters\n",
    "\n",
    "def compute_feats(image, kernels):\n",
    "    feats = np.zeros((len(kernels), 2), dtype=np.double)\n",
    "    for k, kernel in enumerate(kernels):\n",
    "        filtered = ndi.convolve(image, kernel, mode='wrap')\n",
    "        #feats[k, 0] = filtered.mean()\n",
    "        #feats[k, 1] = filtered.var()\n",
    "        feats[k, 0] = kurtosis(np.reshape(filtered,-1))\n",
    "        feats[k, 1] = skew(np.reshape(filtered,-1))\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 9___\n",
    "\n",
    "#Define the type of Gabor filters we want to use\n",
    "\n",
    "kernels = []\n",
    "\n",
    "for sigma in (1,4):\n",
    "    theta = np.pi/4       #Here theta is set to 45 degrees (pi/4 radians) for all filters\n",
    "    for frequency in (0.05, 0.25):\n",
    "        print('theta = {}, sigma = {} frequency = {}'.format(theta, sigma, frequency) )\n",
    "        kernel = np.real(gabor_kernel(frequency,theta=theta,sigma_x=sigma, sigma_y=sigma))\n",
    "        kernels.append(kernel)\n",
    "                         \n",
    "np.shape(kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# ___Cell no. 10___\n",
    "\n",
    "zebra_feats = np.zeros((len(zebra_images),9)) #Create an array to store our 8 features and the image class\n",
    "for i, image in enumerate(zebra_images):\n",
    "    im = plt.imread(image,format='jpeg')\n",
    "    if len(im.shape) > 2:\n",
    "        imean = im.mean(axis=2)\n",
    "    else:\n",
    "        imean = im\n",
    "    imfeats = compute_feats(imean,kernels).reshape(-1) #Call the function to perform feature extraction\n",
    "    zebra_feats[i,:-1] = imfeats \n",
    "    zebra_feats[i,-1] = 1        #Class 1 assigned for all zebra images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# ___Cell no. 11___\n",
    "\n",
    "nozebra_feats = np.zeros((len(nozebra_images),9)) #Create an array to store our 8 features and the image class\n",
    "for i, image in enumerate(nozebra_images):\n",
    "    im = plt.imread(image,format='jpeg')\n",
    "    imfeats = compute_feats(im.mean(axis=2),kernels).reshape(-1)\n",
    "    nozebra_feats[i,:-1] = imfeats \n",
    "    nozebra_feats[i,-1] = 0      #Class 0 assigned for all nozebra images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 12___\n",
    "\n",
    "#combine the datasets\n",
    "ds = np.concatenate((nozebra_feats,zebra_feats), axis=0)\n",
    "features = ds[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 13___\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "features = MaxAbsScaler().fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 14___\n",
    "\n",
    "target = ds[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 15___\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 16___\n",
    "\n",
    "# Randomly splits the data and respective labels (y values) into a train and test set, the size of the\n",
    "# test set is specified to be 20%\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,target,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 17___\n",
    "\n",
    "#Check the sizes of our training and test sets\n",
    "\n",
    "print('Training data and target sizes: \\n{}, {}'.format(X_train.shape,y_train.shape))\n",
    "print('Test data and target sizes: \\n{}, {}'.format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 18___\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Defining the model\n",
    "#C = 1.0  # SVM regularization parameter\n",
    "\n",
    "models = (svm.SVC(kernel='linear'),\n",
    "            svm.SVC(kernel='sigmoid', gamma=1),\n",
    "            svm.SVC(kernel='rbf', gamma=1),\n",
    "            svm.SVC(kernel='poly', degree=1))\n",
    "a = []\n",
    "b = []\n",
    "for clf in models:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_predtrain = clf.predict(X_train)\n",
    "    a.append(metrics.accuracy_score(y_train , y_predtrain))\n",
    "    b.append(metrics.accuracy_score(y_test , y_pred))\n",
    "    \n",
    "d = {\"Model\":models,\"Test prediction\":b, \"Train prediction\":a}\n",
    "M = pd.DataFrame(d)\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the rbf gives us the higher test and train  accuracy then  we uwe it for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 19___\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(C=1,kernel='rbf',gamma=1)\n",
    "#fit to the training data\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 20___\n",
    "\n",
    "# now to Now predict the value of the digit on the test data\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 21___\n",
    "\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "km=metrics.confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(km)\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('SVM RBF Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test,y_pred)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 22___\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_jobs=4, n_estimators=10, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 20___\n",
    "\n",
    "# now to Now predict the value of the digit on the test data\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "km=metrics.confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(km)\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('SVM RBF Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test,y_pred)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 22___\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "DATADIR = r'./downloads/'\n",
    "CATEGORIES = ['house', 'tree']\n",
    "\n",
    "\n",
    "for category in CATEGORIES:  # do dogs and cats\n",
    "    path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "    for img in os.listdir(path):  # iterate over each image per dogs and cats\n",
    "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "        plt.imshow(img_array, cmap='gray')  # graph it\n",
    "        plt.show() \n",
    "        \n",
    "        break  # we just want one for now so break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # do dogs and cats\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in os.listdir(path):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data1 = []\n",
    "\n",
    "def create_training_data1():\n",
    "#     for category in CATEGORIES:  # do dogs and cats\n",
    "\n",
    "    path = zebrafolder # create path to dogs and cats\n",
    "    for zebra in zebrafolder:\n",
    "        class_num = zebrafolder.index(zebra)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in os.listdir(path):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data1.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_training_data1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)\n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data1)\n",
    "for sample in training_data1[:10]:\n",
    "    print(sample[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data1:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================================== \n",
    "# BUILDING CONVOLUTION NEURAL NETWORK\n",
    "# ====================================================================== \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization,Activation\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "dense_layers = [0,1,2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model_cnn = Sequential()\n",
    "\n",
    "            # Layer1:  Convolution + Max Pooling + Batch Normalization + dropout\n",
    "            model_cnn.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model_cnn.add(Activation('relu'))\n",
    "            model_cnn.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "            model_cnn.add(BatchNormalization())\n",
    "            model_cnn.add(Dropout(0.2))\n",
    "\n",
    "            # Layer2:  Convolution + Max Pooling + Batch Normalization + dropout\n",
    "            for l in range(conv_layer-1):\n",
    "                model_cnn.add(Conv2D(layer_size, (3, 3)))\n",
    "                model_cnn.add(Activation('relu'))\n",
    "                model_cnn.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "                model_cnn.add(BatchNormalization())\n",
    "                model_cnn.add(Dropout(0.2))\n",
    "\n",
    "        #     # Layer3:  Convolution + Max Pooling + Batch Normalization + dropout\n",
    "        #     model_cnn.add(Conv2D(256, (3, 3),input_shape = [256,256,3], kernel_regularizer=l2(0.001)))\n",
    "        #     model_cnn.add(Activation('relu'))\n",
    "        #     model_cnn.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "        #     model_cnn.add(BatchNormalization())\n",
    "        #     model_cnn.add(Dropout(0.2))\n",
    "\n",
    "            # Flatten the output to 1-D\n",
    "            model_cnn.add(Flatten())\n",
    "            for _ in range(dense_layer):\n",
    "\n",
    "                # Layer4: Running a simple NN with 3 layers\n",
    "                # NN1\n",
    "                model_cnn.add(Dense(layer_size))\n",
    "                model_cnn.add(Activation('relu'))\n",
    "                model_cnn.add(Dropout(0.2))\n",
    "\n",
    "            # NN2\n",
    "            model_cnn.add(Dense(1))\n",
    "            model_cnn.add(Activation('relu'))\n",
    "            model_cnn.add(Dropout(0.2))\n",
    "\n",
    "        #     # NN3\n",
    "        #     model_cnn.add(Dense(units = 128, activation = 'relu' ,kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        #     model_cnn.add(Dropout(0.2))\n",
    "\n",
    "            #output\n",
    "            model_cnn.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "            # ====================================================================== \n",
    "            # COMPILING CONVOLUTION NEURAL NETWORK\n",
    "            # ====================================================================== \n",
    "            from tensorflow.keras.optimizers import Adam\n",
    "            opt = Adam(lr=0.0005) #Learning rate is half of the default\n",
    "            model_cnn.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "            model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.fit(X,y,epochs=3,batch_size=100,validation_split=0.3,callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.save('64x3_CNN2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = ['house', 'tree']\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZEw = 150  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZEw, IMG_SIZEw))\n",
    "    return new_array.reshape(-1, IMG_SIZEw, IMG_SIZEw, 1)\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(\"64x3_CNN2.model\")\n",
    "filename = input('Enter the name of the image: ')\n",
    "prediction = model.predict([prepare(filename)])\n",
    "print(prediction)  # will be a list in a list.\n",
    "print(CATEGORIES[int(prediction[0][0])])\n",
    "\n",
    "display(Image(filename, height=180, width=180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = ['dog','cat']\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZEw = 150  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZEw, IMG_SIZEw))\n",
    "    return new_array.reshape(-1, IMG_SIZEw, IMG_SIZEw, 1)\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(\"64x3_CNN1.model\")\n",
    "filename = input('Enter the name of the image: ')\n",
    "prediction = model.predict([prepare(filename)])\n",
    "print(prediction)  # will be a list in a list.\n",
    "print(CATEGORIES[int(prediction[0][0])])\n",
    "\n",
    "display(Image(filename, height=180, width=180))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = ['dog','cat']\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZEw = 150  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZEw, IMG_SIZEw))\n",
    "    return new_array.reshape(-1, IMG_SIZEw, IMG_SIZEw, 1)\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(\"64x3_CNN.model\")\n",
    "filename = input('Enter the name of the image: ')\n",
    "prediction = model.predict([prepare(filename)])\n",
    "print(prediction)  # will be a list in a list.\n",
    "print(CATEGORIES[int(prediction[0][0])])\n",
    "\n",
    "display(Image(filename, height=180, width=180))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = ['house', 'tree']\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZEw = 150  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZEw, IMG_SIZEw))\n",
    "    return new_array.reshape(-1, IMG_SIZEw, IMG_SIZEw, 1)\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(\"64x3-CNN.model\")\n",
    "filename = input('Enter the name of the image: ')\n",
    "prediction = model.predict([prepare(filename)])\n",
    "print(prediction)  # will be a list in a list.\n",
    "print(CATEGORIES[int(prediction[0][0])])\n",
    "\n",
    "display(Image(filename, height=180, width=180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
